# AWS Capstone Project â€“ ETL Data Pipeline with Terraform

This project is a fully automated **ETL Data Pipeline on AWS**, built using **Terraform** for Infrastructure-as-Code. It demonstrates how to ingest, transform, and report on e-commerce data using modern cloud-native tools.

---

## ğŸš€ Project Overview
The pipeline is designed to:
1. **Ingest Data** â€“ Data is uploaded to an S3 bucket.  
2. **Trigger Processing** â€“ An AWS Lambda function is invoked automatically.  
3. **Orchestrate Workflow** â€“ The Lambda triggers an AWS Step Function to coordinate tasks.  
4. **Transform Data** â€“ AWS Glue performs cleaning, joins, and transformations.  
5. **Catalog & Query** â€“ A Glue Crawler updates the Data Catalog, enabling queries in Athena.  
6. **Generate Reports** â€“ Lambda functions create summary reports (by category, by payment method, counts) and store them back in S3.  

This project highlights **event-driven architecture, ETL orchestration, serverless compute, and Infrastructure-as-Code**.

---

## ğŸ—ï¸ Architecture
- **AWS S3** â€“ Data lake storage for raw and processed data.  
- **AWS Lambda** â€“ Custom ETL/reporting functions written in Python.  
- **AWS Glue** â€“ Transformation jobs for scalable data processing.  
- **AWS Step Functions** â€“ Orchestration of ETL workflows.  
- **AWS Glue Crawler** â€“ Automated schema discovery for Athena queries.  
- **Athena** â€“ SQL-based querying on curated datasets.  
- **IAM** â€“ Fine-grained access control.  
- **Terraform** â€“ End-to-end infrastructure automation.

---

## ğŸ“‚ Repository Structure

aws-capstone-project
â”‚ .gitignore
â”‚ .terraform.lock.hcl
â”‚ backend.tf
â”‚ main.tf
â”‚ outputs.tf
â”‚ README.md
â”‚ variables.tf
â”‚
â”œâ”€â”€ .github
â”‚ â””â”€â”€ workflows
â”‚ â””â”€â”€ terraform.yml # GitHub Actions workflow for CI/CD
â”‚
â””â”€â”€ modules
â”œâ”€â”€ crawler # Glue Crawler setup
â”‚ â””â”€â”€ main.tf
â”œâ”€â”€ glue # Glue Job definitions
â”‚ â””â”€â”€ main.tf
â”œâ”€â”€ iam # IAM Roles & Policies
â”‚ â””â”€â”€ main.tf
â”œâ”€â”€ lambda # Python Lambda functions + Terraform
â”‚ â”œâ”€â”€ by_payment_methods_lambda.py
â”‚ â”œâ”€â”€ categories_report.py
â”‚ â”œâ”€â”€ counts_report.py
â”‚ â”œâ”€â”€ Trigger_Step_Function.py
â”‚ â””â”€â”€ main.tf
â”œâ”€â”€ s3 # S3 bucket setup
â”‚ â””â”€â”€ main.tf
â””â”€â”€ step_function # Step Function workflow
â””â”€â”€ main.tf

---

## ğŸ“Š Workflow
1. A new file is uploaded to **S3**.  
2. The upload triggers a **Lambda function**.  
3. Lambda calls the **Step Function**, which orchestrates the pipeline.  
4. **Glue Crawlers** update the Data Catalog.  
5. **Glue Jobs** transform raw data into structured tables.  
6. **Athena** queries generate insights.  
7. Lambda functions prepare and store reports.

---

## âœ… Features
- Fully automated, event-driven pipeline.
- Modular Terraform design for reusability.
- Secure IAM roles and least-privilege access.
- CI/CD pipeline for Terraform deployment.
- Python-based reporting with aggregation (e.g., by category, by payment method).

---

## ğŸ“¦ Deployment
### Prerequisites
- Terraform >= 1.3  
- AWS CLI configured with appropriate credentials  
- Python 3.11  

## Steps
```bash
# Clone the repository
git clone https://github.com/piyushmendhe/aws-capstone-project.git
cd aws-capstone-project

# Initialize Terraform
terraform init

# Review the plan
terraform plan

# Deploy infrastructure
terraform apply
```

## ğŸ“ˆ Example Reports

Category Report: Aggregates sales by product category.

Payment Method Report: Counts and trends of payment methods.

Counts Report: Summarized transactions and customer counts.

All reports are stored back into S3 for downstream analytics.

## ğŸ¯ What This Project Demonstrates

Expertise in Data Engineering with AWS.

Ability to design modular, production-grade pipelines.

Strong skills in Terraform, Python, and Cloud ETL workflows.

Hands-on experience with event-driven architectures.

## ğŸ¤ Contributing

Contributions are welcome! Please fork the repo and submit a pull request.


